{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec91d469-c497-4a6b-8823-f392d1dbafc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d5b7be1-ad0b-47c1-89b8-fe6c92e6fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    " %reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c067829-e9d5-47a2-a876-d90ad5179094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adzhumurat_hw_solution_05.ipynb',\n",
       " 'homework.md',\n",
       " 'utils.py',\n",
       " 'adzhumurat_hw4_solution.md',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = '/Users/username/PycharmProjects/llm-zoomcamp/cohorts/2024/04-monitoring'\n",
    "\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed87e25-1eca-4922-80d2-ac1da578e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d28700b-5a21-4732-9351-d72b5d5edcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_llm': 'You can sign up for the course by visiting the course page at [http://mlzoomcamp.com/](http://mlzoomcamp.com/).',\n",
       " 'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository thereâ€™s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       " 'document': '0227b872',\n",
       " 'question': 'Where can I sign up for the course?',\n",
       " 'course': 'machine-learning-zoomcamp'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '04-monitoring/data'\n",
    "filename = 'results-gpt4o-mini.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}/{filename}?raw=1'\n",
    "\n",
    "res = get_ground_truth(ground_truth_url, os.path.join(data_dir, filename))[:300]\n",
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10059d35-2e26-4c8f-a58a-95b132f4d8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "huggingface model loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/username/.pyenv/versions/3.10.13/envs/llmops-env/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'cached_download' (from 'huggingface_hub.file_download') is deprecated and will be removed from version '0.26'. Use `hf_hub_download` instead.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4889f33b983f4e6d97cc8125fd59dfd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/791 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3553c781e18e4fa0b1ce17de80a19ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb99e82ee37e4571ba954c9acdb1ca39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52a3e4c8a0146f8ad67ab244be78dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616caa0e0ff744d98a0d9f29f01eb1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c2e7fd0b204e479bed4e9506bbe867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data_config.json:   0%|          | 0.00/25.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c60babc7794277a8eb20e785e233e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccd64eb145843ba93592688b492a125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6e3eeff21048698e10f3a9689d9fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f283287252747e4ac801a8a418d9700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9e60dab7cf40d19737cab8f38b9a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b4e53f9732476c936b140c48b474b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4a8be8e2ba454bbb988bb1c9b7b7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_script.py:   0%|          | 0.00/13.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de68038ca35467c88e0f2192363d730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6800b57f85af4855a2d0c7d018a204c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.2.2. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loadind done\n"
     ]
    }
   ],
   "source": [
    "from utils import get_or_create_embedder\n",
    "\n",
    "model_name = 'multi-qa-mpnet-base-dot-v1'\n",
    "embedder = get_or_create_embedder(data_dir, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0d900f-dfe3-4015-8f3a-1746cd5e2e7a",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b024d70-97d0-48ad-82e9-7503f7218bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: first coord: -0.422\n"
     ]
    }
   ],
   "source": [
    "answer_llm = res[0]['answer_llm']\n",
    "corpus_texts = [\n",
    "    answer_llm\n",
    "]\n",
    "passage_embeddings = embedder.encode(corpus_texts, show_progress_bar=False)\n",
    "\n",
    "print('Q1: first coord: %.3f' % passage_embeddings[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5614a36-36ae-4de2-a928-439e902be71b",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af96d07e-f57d-4d8d-8137-b13baa6303d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 300\n"
     ]
    }
   ],
   "source": [
    "answers_llm = [i['answer_llm'] for i in res]\n",
    "answers_orig = [i['answer_orig'] for i in res]\n",
    "print(len(answers_llm), len(answers_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f7d749ac-0530-418c-980e-0563c5f2eb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ef6f4e18994c65acc701e5d387d770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2602905b9814d8a81777d3b2acd9b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 768) (300, 768)\n"
     ]
    }
   ],
   "source": [
    "answers_llm_embeds = embedder.encode(answers_llm, show_progress_bar=True)\n",
    "answers_orig_embeds = embedder.encode(answers_orig, show_progress_bar=True)\n",
    "print(answers_llm_embeds.shape, answers_orig_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e505f452-e890-4d87-b9d1-3b8a713f99ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1830,) 32.38980007171631\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_scores(A, B):\n",
    "    scores_ = np.array([np.dot(A[i], B[i]) for i in range(A.shape[0])])\n",
    "    return scores_\n",
    "\n",
    "scores = get_scores(answers_llm_embeds, answers_orig_embeds)\n",
    "print(scores.shape, np.percentile(scores, 75))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d7a87-a137-495f-9207-9544f5f1b072",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "888f1510-1098-4034-8807-d51201790cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num scores 300, q75: 0.8362\n"
     ]
    }
   ],
   "source": [
    "def normed_vector(v):\n",
    "    norm = np.sqrt((v * v).sum())\n",
    "    v_norm = v / norm\n",
    "    return v_norm\n",
    "\n",
    "def normalize_embeds(embeds_input):\n",
    "    embeds_normed = np.vstack([normed_vector(embeds_input[i]) for i in range(embeds_input.shape[0])])\n",
    "    return embeds_normed\n",
    "\n",
    "answers_llm_embeds_normed = normalize_embeds(answers_llm_embeds)\n",
    "answers_orig_embeds_normed = normalize_embeds(answers_orig_embeds)\n",
    "\n",
    "scores_normed = get_scores(answers_llm_embeds_normed, answers_orig_embeds_normed)\n",
    "print('Num scores %d, q75: %.4f' % (scores_normed.shape[0], np.percentile(scores_normed, 75)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f1fe5f-7ed4-4ab1-9422-e991f3736336",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "14fb2a06-0d77-49db-b619-d9b4845299d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4: Best F-score 0.455\n",
      "{'answer_llm': \"Yes, all sessions are recorded, so if you miss one, you won't miss anything. You can catch up on the content later. Additionally, you can submit your questions in advance for office hours, and those sessions are also recorded.\", 'answer_orig': 'Everything is recorded, so you wonâ€™t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.', 'document': '5170565b', 'question': 'Are sessions recorded if I miss one?', 'course': 'machine-learning-zoomcamp'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.45454545454545453,\n",
       "  'p': 0.45454545454545453,\n",
       "  'f': 0.45454544954545456},\n",
       " 'rouge-2': {'r': 0.21621621621621623,\n",
       "  'p': 0.21621621621621623,\n",
       "  'f': 0.21621621121621637},\n",
       " 'rouge-l': {'r': 0.3939393939393939,\n",
       "  'p': 0.3939393939393939,\n",
       "  'f': 0.393939388939394}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "r = res[10]\n",
    "\n",
    "scores = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]\n",
    "\n",
    "print('Q4: Best F-score %.3f'% scores['rouge-1']['f'])\n",
    "\n",
    "print(r)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ea32a9-c567-4abc-889f-256ac750fd53",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38fc6e1e-bf08-4009-85d3-44932ab9785c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35490034990035496"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_average_score(scores, metric='f', score_list = None):\n",
    "    if score_list is None:\n",
    "        score_list = scores.keys()\n",
    "    res = np.mean([scores[k][metric] for k in scores if k in score_list])\n",
    "    return res\n",
    "eval_average_score(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf0d942-b575-4a01-bc42-530c540b6678",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6fd3f460-10ab-4bd3-8235-b97da1874051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.313205367339838\n"
     ]
    }
   ],
   "source": [
    "scores_all_points = [\n",
    "    eval_average_score(rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0])\n",
    "    for r in res\n",
    "]\n",
    "print(np.mean(scores_all_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd01d39e-57cb-4c7f-87e8-334fcca774d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  You can sign up for the course by visiting the...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                              question                     course  \n",
       "0  Where can I sign up for the course?  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "res_df = pd.DataFrame(res)\n",
    "res_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d3ea4543-1f81-42b6-8929-996ed1a4cc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_llm': 'You can sign up for the course by visiting the course page at [http://mlzoomcamp.com/](http://mlzoomcamp.com/).',\n",
       " 'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository thereâ€™s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       " 'document': '0227b872',\n",
       " 'question': 'Where can I sign up for the course?',\n",
       " 'course': 'machine-learning-zoomcamp'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f6838cc1-ace2-42b0-9b95-6c2eddabf263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'rouge-1': {'r': 0.061224489795918366, 'p': 0.21428571428571427, 'f': 0.09523809178130524}, 'rouge-2': {'r': 0.017543859649122806, 'p': 0.07142857142857142, 'f': 0.028169010918468917}, 'rouge-l': {'r': 0.061224489795918366, 'p': 0.21428571428571427, 'f': 0.09523809178130524}}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_scores_array = res_df[['answer_llm', 'answer_orig']].apply(lambda x: rouge_scorer.get_scores(x.iloc[0], x.iloc[1])[0], axis=1).values\n",
    "\n",
    "dataset_scores_array[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9de44c-fb4a-446b-8a9e-5c458eb61e8c",
   "metadata": {},
   "source": [
    "Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f6937c55-ec7d-434a-b19b-301429424092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge_1</th>\n",
       "      <th>rouge_2</th>\n",
       "      <th>rouge_l</th>\n",
       "      <th>rouge_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.072882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.091435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.327658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.150821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.142076</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.120219</td>\n",
       "      <td>0.098731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rouge_1   rouge_2   rouge_l  rouge_avg\n",
       "0  0.095238  0.028169  0.095238   0.072882\n",
       "1  0.125000  0.055556  0.093750   0.091435\n",
       "2  0.415584  0.177778  0.389610   0.327658\n",
       "3  0.216216  0.047059  0.189189   0.150821\n",
       "4  0.142076  0.033898  0.120219   0.098731"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_df_entry(scores):\n",
    "    rouge_1 = scores['rouge-1']['f']\n",
    "    rouge_2 = scores['rouge-2']['f']\n",
    "    rouge_l = scores['rouge-l']['f']\n",
    "    rouge_avg = (rouge_1 + rouge_2 + rouge_l) / 3\n",
    "\n",
    "    return (rouge_1, rouge_2, rouge_l, rouge_avg)\n",
    "\n",
    "scores_df = pd.DataFrame([prepare_df_entry(i) for i in dataset_scores_array], columns=['rouge_1', 'rouge_2', 'rouge_l', 'rouge_avg'])\n",
    "\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "139e71ca-fd1b-4af2-86bb-3f6d91761797",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = [eval_average_score(i) for i in rouge_scorer.get_scores([r['answer_llm'] for r in res], [r['answer_orig'] for r in res])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c9ae2db7-7e7b-4f06-9448-35f73b7451cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20696501983423318"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df['rouge_2'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a4ab89-a402-411d-8d2c-1748fbb0dcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
